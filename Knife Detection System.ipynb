{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3850775f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorflow==2.5.0\n",
    "#!pip install utils\n",
    "#!pip install opencv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282f9758",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/ultralytics/yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec72711",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d28bebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m pip install pandas\n",
    "#!pip install onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aae86149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import utils\n",
    "import cv2\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f88365ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0de3e7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SK\\Desktop\\Object_Detect1\\YOLOv5\n"
     ]
    }
   ],
   "source": [
    "%cd YOLOv5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b07b321a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c035226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python export.py --weights .\\YOLOv5s.pt --include onnx --simplify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a352e78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNet('YOLOv5s.onnx')\n",
    "layer_Names = net.getLayerNames()\n",
    "outputNames = [layer_Names[i - 1] for i in net.getUnconnectedOutLayers()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "890bd27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mime stands for mulitpurpose internet mail extension\n",
    "from email.mime import multipart \n",
    "import os \n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.base import MIMEBase\n",
    "from email.mime.image import MIMEImage # to accomodate image attachment\n",
    "from email import encoders\n",
    "\n",
    "\n",
    "username = 'sk.cephas.0852@gmail.com'\n",
    "password = 'mufzcsvyptbliblx' # the 16 digit character which we got from myaccounts.google.com\n",
    "\n",
    "\n",
    "# defining a function to send a mail with attachment (picture)\n",
    "\n",
    "def send_mail(text=\"Knife detected!!\", subject=\"Cam capture\",from_email= \"sk.cephas.0852@gmail.com\",to_emails=None, html=None,attachment=None,):\n",
    "   \n",
    "    assert isinstance(to_emails, list)\n",
    "    msg = MIMEMultipart()\n",
    "    msg['From'] = str(from_email)\n",
    "    msg['To'] = \", \".join(str(to_emails))\n",
    "    msg['Subject'] = subject\n",
    "\n",
    "    # reading the image\n",
    "    with open(attachment, 'rb') as f:\n",
    "        img_data = f.read()\n",
    "\n",
    "    txt_part = MIMEText(text, 'plain')\n",
    "    msg.attach(txt_part)\n",
    "    image = MIMEImage(img_data, name=os.path.basename(attachment)) \n",
    "    msg.attach(image)\n",
    "    msg_str = msg.as_string()\n",
    "   \n",
    "    \n",
    "    # server side coding\n",
    "    server = smtplib.SMTP(host='smtp.gmail.com',port=587)\n",
    "    server.ehlo()\n",
    "    server.starttls()\n",
    "    server.login(username, password)\n",
    "    server.sendmail(from_email,list(to_emails),msg_str)\n",
    "    server.quit() # quits the server\n",
    "\n",
    "\n",
    "send_mail(to_emails=['sk.cephas.0852@gmail.com','lucienneawoudi16@gmail.com'],attachment='C:/Users/SK/Desktop/Object_Detect1/YOLOv5/attachments/k6.jpg') #note that we need pass the mail as a list data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d7f8ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_yolov5(source):\n",
    "        \n",
    "        ret, img = video.read()\n",
    "        img_h, img_w, _  = img.shape \n",
    "        \n",
    "        while video.isOpened():\n",
    "            frame_count+=1\n",
    "\n",
    "    # put the image in square big enough\n",
    "        col, row, _ = source.shape\n",
    "        _max = max(col, row)\n",
    "        resized = np.zeros((_max, _max, 3), np.uint8)\n",
    "        resized[0:col, 0:row] = source\n",
    "    \n",
    "    # resize to 640x640, normalize to [0,1[ and swap Red and Blue channels\n",
    "        result = cv2.dnn.blobFromImage(resized, 1.0/255.0, (640, 640), swapRB=True)\n",
    "        net.setInput(result)\n",
    "        #output = net.forward()\n",
    "    \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d59b91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting twilio\n",
      "  Downloading twilio-7.15.0-py2.py3-none-any.whl (1.4 MB)\n",
      "Requirement already satisfied: pytz in c:\\programdata\\anaconda3\\lib\\site-packages (from twilio) (2021.3)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from twilio) (2.27.1)\n",
      "Requirement already satisfied: PyJWT<3.0.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from twilio) (2.1.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.0.0->twilio) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.0.0->twilio) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.0.0->twilio) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.0.0->twilio) (2021.10.8)\n",
      "Installing collected packages: twilio\n",
      "Successfully installed twilio-7.15.0\n"
     ]
    }
   ],
   "source": [
    "!pip install twilio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b405a17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the helper library from https://www.twilio.com/docs/python/install\n",
    "import os\n",
    "from twilio.rest import Client\n",
    "\n",
    "                     # Find your Account SID and Auth Token in Account Info\n",
    "                     # and set the environment variables. See http://twil.io/secure\n",
    "                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "227e869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unwrap_detection(input_image, output_data):\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "\n",
    "    rows = output_data.shape[0]\n",
    "\n",
    "    image_width, image_height, _ = input_image.shape\n",
    "\n",
    "    x_factor = image_width / 640\n",
    "    y_factor =  image_height / 640\n",
    "\n",
    "    for r in range(rows):\n",
    "        row = output_data[r]\n",
    "        confidence = row[4]\n",
    "        \n",
    "        if confidence >= 0.4:\n",
    "\n",
    "            classes_scores = row[5:]\n",
    "            _, _, _, max_indx = cv2.minMaxLoc(classes_scores)\n",
    "            class_id = max_indx[1]\n",
    "            if (classes_scores[class_id] > .25):\n",
    "\n",
    "                confidences.append(confidence)\n",
    "\n",
    "                class_ids.append(class_id)\n",
    "                \n",
    "                x, y, w, h = row[0].item(), row[1].item(), row[2].item(), row[3].item() \n",
    "                left = int((x - 0.5 * w) * x_factor)\n",
    "                top = int((y - 0.5 * h) * y_factor)\n",
    "                width = int(w * x_factor)\n",
    "                height = int(h * y_factor)\n",
    "                box = np.array([left, top, width, height])\n",
    "                boxes.append(box)\n",
    "                    \n",
    "            return class_ids, confidences, boxes\n",
    "         print(unwrap_detection)\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf10a5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sms(note):\n",
    "    \n",
    "    account_sid = os.environ['ACeab585e6ab1df6092551ea6fac87369e']\n",
    "    auth_token = os.environ['ba480387eae35f0e106cf48b194f9106']\n",
    "    client = Client(account_sid, auth_token)\n",
    "    message = client.messages.create(\n",
    "    body='Knife Detected',\n",
    "    from_='+14632588241',\n",
    "    to='+233542941448'\n",
    "     )\n",
    "\n",
    "    \n",
    "    \n",
    "    if(class_ids.append(class_id) ==\"knife\"): \n",
    "        print(message.sid)\n",
    "        sms(note)\n",
    "    else:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6f15e02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=yolov5s.pt, source=0, data=data\\coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs\\detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5  v6.2-195-gdf80e7c Python-3.9.12 torch-1.12.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "[ WARN:0@13.803] global D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\videoio\\src\\cap_msmf.cpp (464) `anonymous-namespace'::SourceReaderCB::OnReadSample videoio(MSMF): OnReadSample() is called with error status: -1072875772\n",
      "[ WARN:0@13.803] global D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\videoio\\src\\cap_msmf.cpp (476) `anonymous-namespace'::SourceReaderCB::OnReadSample videoio(MSMF): async ReadSample() call is failed with error status: -1072875772\n",
      "[ WARN:1@13.803] global D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\videoio\\src\\cap_msmf.cpp (1752) CvCapture_MSMF::grabFrame videoio(MSMF): can't grab frame. Error: -1072875772\n",
      "1/1: 0...  Success (inf frames 640x480 at 30.00 FPS)\n",
      "[ WARN:2@13.805] global D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\videoio\\src\\cap_msmf.cpp (1752) CvCapture_MSMF::grabFrame videoio(MSMF): can't grab frame. Error: -1072875772\n",
      "\n",
      "Traceback (most recent call last):\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "  File \"C:\\Users\\SK\\Desktop\\Object_Detect1\\YOLOv5\\detect.py\", line 258, in <module>\n",
      "    main(opt)\n",
      "  File \"C:\\Users\\SK\\Desktop\\Object_Detect1\\YOLOv5\\detect.py\", line 253, in main\n",
      "    run(**vars(opt))\n",
      "  File \"C:\\Users\\SK\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\autograd\\grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\SK\\Desktop\\Object_Detect1\\YOLOv5\\detect.py\", line 103, in run\n",
      "    dataset = LoadStreams(source, img_size=imgsz, stride=stride, auto=pt, vid_stride=vid_stride)\n",
      "  File \"C:\\Users\\SK\\Desktop\\Object_Detect1\\YOLOv5\\utils\\dataloaders.py\", line 377, in __init__\n",
      "    s = np.stack([letterbox(x, img_size, stride=stride, auto=auto)[0].shape for x in self.imgs])\n",
      "  File \"C:\\Users\\SK\\Desktop\\Object_Detect1\\YOLOv5\\utils\\dataloaders.py\", line 377, in <listcomp>\n",
      "    s = np.stack([letterbox(x, img_size, stride=stride, auto=auto)[0].shape for x in self.imgs])\n",
      "  File \"C:\\Users\\SK\\Desktop\\Object_Detect1\\YOLOv5\\utils\\augmentations.py\", line 113, in letterbox\n",
      "    shape = im.shape[:2]  # current shape [height, width]\n",
      "AttributeError: 'NoneType' object has no attribute 'shape'\n"
     ]
    }
   ],
   "source": [
    "!python detect.py --source 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b5f710",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
